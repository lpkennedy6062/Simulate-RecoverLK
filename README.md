This project looks to test a simulate-and-recover program for the EZ diffusion model. The objective is to determine whether the EZ diffusion model can accurately estimate parameters from data that were generated by the same model. Essentially, this test is used to check consistency in cognitive modeling.

This repository includes a simulation script that generates diffusion model data, a recovery process that estimates the original parameters, and a test script that validates the model's performance. The repository's structure is as follows, with two separate embedded folders, one being the src folder and the other being the test folder. In the src folder there is the code for my forward definition, my inverse definition, my simulate and recover initial script, and a main.sh file that runs simulate and recover. In my test folder I have just two files, one of which is my created tests for simulate and recover and my second is the test.sh file which runs the test-sm file.
The expected results for this test would be having bias averaging around 0 across iterations. Also the squared error should decrease as the sample size (N) increases. 

I would argue that if the EZ diffusion model is accurate and consistent, the recovered parameters should closely match the true parameters. When increasing the sample size, the model should become more accurate when looking at parameter estimation.
In order to assess and properly test these results, I implemented some tests which look to revise inputs and outputs to make sure they are correct.

Some conclusions that can be gained from this model is more insight into its accuracy, consistency, and limitations. When looking into the consistency of the EZ diffusion model, the bias averaged around 0, meaning that across many simulations, the model didn't overestimate or underestimate the parameters. This means that my model was internally consistent, meaning it can recover its original true parameters. When looking at the data's sample size, as it increases the squared error decreases, confirming the idea that larger datasets increase reliability and decrease noise. While this model is somewhat complex, it is still a simplified version of full diffusion models which are able to account for more variables like trial-by-trial variability and utilize a starting point bias. These full models are able to be more generalized and precise, leading to more accurate data and more confidence in results.

Overall, the EZ diffusion model is an influential tool for estimating parameters from observed summary statistics. This test helps to prove the claim that if data is created by the EZ model, then the estimation procedure will reliably recover the original parameters. Additionally, the inverse model is able to find the actual parameters with minimal bias, further validating its accuracy. When looking at both the forward and inverse models together, it shows that they are both equivalent and successful in their calculations. This confirms that the EZ Diffusion model is consistent, reliable, and strongly suited for cognitive modeling applications. 

I utilized ChatGPT when first implementing the equations and brainstorming my test cases. It also helped me with solving errors and learning more about bash scripts and how to more efficiently code in VS Code.
